{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorboard in c:\\users\\diego\\miniconda3\\envs\\env_mtg\\lib\\site-packages (2.15.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in c:\\users\\diego\\miniconda3\\envs\\env_mtg\\lib\\site-packages (from tensorboard) (2.0.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in c:\\users\\diego\\miniconda3\\envs\\env_mtg\\lib\\site-packages (from tensorboard) (1.59.3)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\diego\\miniconda3\\envs\\env_mtg\\lib\\site-packages (from tensorboard) (2.23.4)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in c:\\users\\diego\\miniconda3\\envs\\env_mtg\\lib\\site-packages (from tensorboard) (1.1.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\diego\\miniconda3\\envs\\env_mtg\\lib\\site-packages (from tensorboard) (3.5.1)\n",
      "Requirement already satisfied: numpy>=1.12.0 in c:\\users\\diego\\miniconda3\\envs\\env_mtg\\lib\\site-packages (from tensorboard) (1.26.1)\n",
      "Requirement already satisfied: protobuf<4.24,>=3.19.6 in c:\\users\\diego\\miniconda3\\envs\\env_mtg\\lib\\site-packages (from tensorboard) (4.23.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\diego\\miniconda3\\envs\\env_mtg\\lib\\site-packages (from tensorboard) (2.31.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\diego\\miniconda3\\envs\\env_mtg\\lib\\site-packages (from tensorboard) (68.0.0)\n",
      "Requirement already satisfied: six>1.9 in c:\\users\\diego\\appdata\\roaming\\python\\python39\\site-packages (from tensorboard) (1.16.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\diego\\miniconda3\\envs\\env_mtg\\lib\\site-packages (from tensorboard) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\diego\\miniconda3\\envs\\env_mtg\\lib\\site-packages (from tensorboard) (3.0.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\diego\\miniconda3\\envs\\env_mtg\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\diego\\miniconda3\\envs\\env_mtg\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\diego\\miniconda3\\envs\\env_mtg\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\diego\\miniconda3\\envs\\env_mtg\\lib\\site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\diego\\appdata\\roaming\\python\\python39\\site-packages (from markdown>=2.6.8->tensorboard) (6.6.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\diego\\miniconda3\\envs\\env_mtg\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\diego\\miniconda3\\envs\\env_mtg\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\diego\\miniconda3\\envs\\env_mtg\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\diego\\miniconda3\\envs\\env_mtg\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard) (2023.11.17)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\diego\\miniconda3\\envs\\env_mtg\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard) (2.1.3)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\diego\\appdata\\roaming\\python\\python39\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.15.0)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in c:\\users\\diego\\miniconda3\\envs\\env_mtg\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.5.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\diego\\miniconda3\\envs\\env_mtg\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "\n",
    "import yaml\n",
    "from net_architectures.lstm import *\n",
    "from net_architectures.mlp import *\n",
    "from gensim.models import Word2Vec\n",
    "import pandas as pd\n",
    "import random\n",
    "#tensorboard --logdir=/home/diego/Documentos/MTG_drafter/17_lands/runs --verbosity 0\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "# Verificar se a GPU está disponível\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_vec_model = Word2Vec.load(\"card2vec.model\")\n",
    "vocab = list(word_to_vec_model.wv.key_to_index.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "df_train = pd.read_csv('dataset/train_set.csv')\n",
    "# Convertendo as strings para listas\n",
    "df_train['pool'] = df_train['pool'].apply(ast.literal_eval)\n",
    "# drop rnan pick\n",
    "df_train = df_train.dropna(subset=['pick'])\n",
    "\n",
    "df_train['label'] = df_train['pick'].apply(lambda x: vocab.index(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Entrada 1 ---\n",
      "232\n",
      "Inputs: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Label: Archon of the Wild Rose\n",
      "Máscara: tensor([[1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "         0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from dataset_class import *\n",
    "\n",
    "# Crie o dataset e o DataLoader\n",
    "dataset = MagicDataset(df_train, word_to_vec_model, vocab)\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "# Itere sobre as primeiras 45 entradas do DataLoader\n",
    "for i, (inputs, labels, mascara) in enumerate(dataloader):\n",
    "    if i < 45:\n",
    "        print(f\"--- Entrada {i+1} ---\")\n",
    "        \n",
    "        # Converta os embeddings para nomes\n",
    "        input_names = [MagicDataset.embedding_para_nome(embedding.numpy(), word_to_vec_model) for embedding in inputs.squeeze(0)]\n",
    "        \n",
    "        # Converta o índice da label para o nome usando a função indice_para_nome\n",
    "        label_name = vocab[labels.item()]\n",
    "        print(labels.item())\n",
    "        print(\"Inputs:\", input_names)\n",
    "        print(\"Label:\", label_name)\n",
    "        print(\"Máscara:\", mascara)\n",
    "        print(\"\\n\")\n",
    "        break\n",
    "    else:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciar o modelo LSTM\n",
    "from torch import nn\n",
    "from net_architectures.mlp import *\n",
    "#model = LSTMModel()\n",
    "model = FeedForwardModel()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter rank == diamond\n",
    "df_train = df_train[df_train['rank'] == 'diamond']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Average Loss: 1.5206, Epoch Acuracy: 0.4534\n",
      "Epoch [2/50], Average Loss: 1.4169, Epoch Acuracy: 0.4694\n",
      "Epoch [3/50], Average Loss: 1.4032, Epoch Acuracy: 0.4726\n",
      "Epoch [4/50], Average Loss: 1.3948, Epoch Acuracy: 0.4755\n",
      "Epoch [5/50], Average Loss: 1.3906, Epoch Acuracy: 0.4772\n",
      "Epoch [6/50], Average Loss: 1.3871, Epoch Acuracy: 0.4775\n",
      "Epoch [7/50], Average Loss: 1.3839, Epoch Acuracy: 0.4779\n",
      "Epoch [8/50], Average Loss: 1.3820, Epoch Acuracy: 0.4793\n",
      "Epoch [9/50], Average Loss: 1.3801, Epoch Acuracy: 0.4795\n",
      "Epoch [10/50], Average Loss: 1.3788, Epoch Acuracy: 0.4808\n",
      "Epoch [11/50], Average Loss: 1.3777, Epoch Acuracy: 0.4804\n",
      "Epoch [12/50], Average Loss: 1.3764, Epoch Acuracy: 0.4812\n",
      "Epoch [13/50], Average Loss: 1.3755, Epoch Acuracy: 0.4812\n",
      "Epoch [14/50], Average Loss: 1.3746, Epoch Acuracy: 0.4813\n",
      "Epoch [15/50], Average Loss: 1.3740, Epoch Acuracy: 0.4815\n",
      "Epoch [16/50], Average Loss: 1.3733, Epoch Acuracy: 0.4818\n",
      "Epoch [17/50], Average Loss: 1.3728, Epoch Acuracy: 0.4817\n",
      "Epoch [18/50], Average Loss: 1.3719, Epoch Acuracy: 0.4829\n",
      "Epoch [19/50], Average Loss: 1.3713, Epoch Acuracy: 0.4824\n",
      "Epoch [20/50], Average Loss: 1.3711, Epoch Acuracy: 0.4828\n",
      "Epoch [21/50], Average Loss: 1.3702, Epoch Acuracy: 0.4826\n",
      "Epoch [22/50], Average Loss: 1.3700, Epoch Acuracy: 0.4833\n",
      "Epoch [23/50], Average Loss: 1.3690, Epoch Acuracy: 0.4833\n",
      "Epoch [24/50], Average Loss: 1.3691, Epoch Acuracy: 0.4831\n",
      "Epoch [25/50], Average Loss: 1.3690, Epoch Acuracy: 0.4834\n",
      "Epoch [26/50], Average Loss: 1.3685, Epoch Acuracy: 0.4837\n",
      "Epoch [27/50], Average Loss: 1.3679, Epoch Acuracy: 0.4839\n",
      "Epoch [28/50], Average Loss: 1.3677, Epoch Acuracy: 0.4833\n",
      "Epoch [29/50], Average Loss: 1.3673, Epoch Acuracy: 0.4837\n",
      "Epoch [30/50], Average Loss: 1.3672, Epoch Acuracy: 0.4832\n",
      "Epoch [31/50], Average Loss: 1.3669, Epoch Acuracy: 0.4839\n",
      "Epoch [32/50], Average Loss: 1.3666, Epoch Acuracy: 0.4841\n",
      "Epoch [33/50], Average Loss: 1.3660, Epoch Acuracy: 0.4838\n",
      "Epoch [34/50], Average Loss: 1.3661, Epoch Acuracy: 0.4841\n",
      "Epoch [35/50], Average Loss: 1.3656, Epoch Acuracy: 0.4847\n",
      "Epoch [36/50], Average Loss: 1.3656, Epoch Acuracy: 0.4845\n",
      "Epoch [37/50], Average Loss: 1.3655, Epoch Acuracy: 0.4840\n",
      "Epoch [38/50], Average Loss: 1.3654, Epoch Acuracy: 0.4842\n",
      "Epoch [39/50], Average Loss: 1.3651, Epoch Acuracy: 0.4841\n",
      "Epoch [40/50], Average Loss: 1.3650, Epoch Acuracy: 0.4846\n",
      "Epoch [41/50], Average Loss: 1.3649, Epoch Acuracy: 0.4842\n",
      "Epoch [42/50], Average Loss: 1.3647, Epoch Acuracy: 0.4849\n",
      "Epoch [43/50], Average Loss: 1.3644, Epoch Acuracy: 0.4846\n",
      "Epoch [44/50], Average Loss: 1.3643, Epoch Acuracy: 0.4847\n",
      "Epoch [45/50], Average Loss: 1.3640, Epoch Acuracy: 0.4843\n",
      "Epoch [46/50], Average Loss: 1.3638, Epoch Acuracy: 0.4845\n",
      "Epoch [47/50], Average Loss: 1.3639, Epoch Acuracy: 0.4849\n",
      "Epoch [48/50], Average Loss: 1.3637, Epoch Acuracy: 0.4847\n",
      "Epoch [49/50], Average Loss: 1.3637, Epoch Acuracy: 0.4847\n",
      "Epoch [50/50], Average Loss: 1.3634, Epoch Acuracy: 0.4848\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mO Kernel falhou ao executar o código na célula atual ou em uma célula anterior. Examine o código nas células para identificar uma possível causa da falha. Clique <a href=\"https://aka.ms/vscodeJupyterKernelCrash\">aqui</a> para obter mais informações. Consulte o <a href='command:jupyter.viewOutput'>log</a> do Jupyter para obter mais detalhes."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from dataset_class import *\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Defina os hiperparâmetros\n",
    "num_epochs = 50\n",
    "batch_size = 64\n",
    "model_name = 'model_1'\n",
    "\n",
    "# Configurar o TensorBoard SummaryWriter para escrever logs na pasta 'runs'\n",
    "log_dir = './runs/'+model_name+'/'\n",
    "writer = SummaryWriter(log_dir=log_dir)\n",
    "\n",
    "# Defina um diretório para salvar os checkpoints\n",
    "checkpoint_dir = 'checkpoints'\n",
    "\n",
    "# Certifique-se de que o diretório exista (ou crie-o)\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir)\n",
    "\n",
    "# Criar o dataset e o DataLoader\n",
    "dataset = MagicDataset(df_train, word_to_vec_model, vocab)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Mover o modelo para a GPU\n",
    "model.to(device)\n",
    "\n",
    "# Ciclo de treinamento\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    for i, (inputs, labels, mascara) in enumerate(dataloader):\n",
    "        # Mover as entradas e rótulos para a GPU\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        mascara = mascara.to(device)\n",
    "\n",
    "        # Zerar os gradientes\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward\n",
    "        outputs = model(inputs, mascara)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Acumular a perda\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Backward\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Calcular acertos\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct_predictions += (predicted == labels).sum().item()\n",
    "        total_samples += labels.size(0)\n",
    "\n",
    "    # Calcular e imprimir a perda média e a acurácia da época\n",
    "    average_loss = total_loss / len(dataloader)\n",
    "    epoch_accuracy = correct_predictions / total_samples\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Average Loss: {average_loss:.4f}, Epoch Acuracy: {epoch_accuracy:.4f}\")\n",
    "\n",
    "    # Registrar no TensorBoard\n",
    "    writer.add_scalar('Epoch Accuracy', epoch_accuracy, epoch)\n",
    "    writer.add_scalar('Epoch Loss', average_loss, epoch)\n",
    "\n",
    "    # Salvar o estado do modelo a cada 5 épocas\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        checkpoint = {\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': average_loss\n",
    "        }\n",
    "        checkpoint_path = os.path.join(checkpoint_dir, f'{model_name}_checkpoint_epoch_{epoch + 1}.pt')\n",
    "        torch.save(checkpoint, checkpoint_path)\n",
    "\n",
    "# Fechar o writer após terminar o treinamento\n",
    "writer.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mtg_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
