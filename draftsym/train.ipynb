{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorboard in c:\\users\\diego\\miniconda3\\envs\\env_mtg\\lib\\site-packages (2.15.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in c:\\users\\diego\\miniconda3\\envs\\env_mtg\\lib\\site-packages (from tensorboard) (2.0.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in c:\\users\\diego\\miniconda3\\envs\\env_mtg\\lib\\site-packages (from tensorboard) (1.59.3)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\diego\\miniconda3\\envs\\env_mtg\\lib\\site-packages (from tensorboard) (2.23.4)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in c:\\users\\diego\\miniconda3\\envs\\env_mtg\\lib\\site-packages (from tensorboard) (1.1.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\diego\\miniconda3\\envs\\env_mtg\\lib\\site-packages (from tensorboard) (3.5.1)\n",
      "Requirement already satisfied: numpy>=1.12.0 in c:\\users\\diego\\miniconda3\\envs\\env_mtg\\lib\\site-packages (from tensorboard) (1.26.1)\n",
      "Requirement already satisfied: protobuf<4.24,>=3.19.6 in c:\\users\\diego\\miniconda3\\envs\\env_mtg\\lib\\site-packages (from tensorboard) (4.23.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\diego\\miniconda3\\envs\\env_mtg\\lib\\site-packages (from tensorboard) (2.31.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\diego\\miniconda3\\envs\\env_mtg\\lib\\site-packages (from tensorboard) (68.0.0)\n",
      "Requirement already satisfied: six>1.9 in c:\\users\\diego\\appdata\\roaming\\python\\python39\\site-packages (from tensorboard) (1.16.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\diego\\miniconda3\\envs\\env_mtg\\lib\\site-packages (from tensorboard) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\diego\\miniconda3\\envs\\env_mtg\\lib\\site-packages (from tensorboard) (3.0.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\diego\\miniconda3\\envs\\env_mtg\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\diego\\miniconda3\\envs\\env_mtg\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\diego\\miniconda3\\envs\\env_mtg\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\diego\\miniconda3\\envs\\env_mtg\\lib\\site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\diego\\appdata\\roaming\\python\\python39\\site-packages (from markdown>=2.6.8->tensorboard) (6.6.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\diego\\miniconda3\\envs\\env_mtg\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\diego\\miniconda3\\envs\\env_mtg\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\diego\\miniconda3\\envs\\env_mtg\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\diego\\miniconda3\\envs\\env_mtg\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard) (2023.11.17)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\diego\\miniconda3\\envs\\env_mtg\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard) (2.1.3)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\diego\\appdata\\roaming\\python\\python39\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.15.0)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in c:\\users\\diego\\miniconda3\\envs\\env_mtg\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.5.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\diego\\miniconda3\\envs\\env_mtg\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from net_architectures.lstm import *\n",
    "from net_architectures.mlp import *\n",
    "from gensim.models import Word2Vec\n",
    "import pandas as pd\n",
    "import random\n",
    "#tensorboard --logdir=/home/diego/Documentos/MTG_drafter/draftsym/runs --verbosity 0\n",
    "\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar se a GPU está disponível\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi = open('config.yaml', 'r')\n",
    "card_dict = yaml.load(fi, Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indice_para_nome(indice, cards_dict):\n",
    "    \"\"\"Converte um índice para o nome da carta correspondente usando o dicionário de cartas.\"\"\"\n",
    "    try:\n",
    "        return cards_dict['cards_list'][indice]\n",
    "    except IndexError:\n",
    "        raise ValueError(f\"Índice {indice} fora do alcance do dicionário de cartas.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train_df.csv')\n",
    "df_train = df_train.drop(columns=['Unnamed: 0.1', 'Unnamed: 0'])\n",
    "#df_train = df_train[:90]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_vec_model = Word2Vec.load(\"card2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Entrada 1 ---\n",
      "235\n",
      "Inputs: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Label: Patient_Rebuilding\n",
      "Máscara: tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from dataset_class import *\n",
    "\n",
    "# Crie o dataset e o DataLoader\n",
    "dataset = MagicDataset(df_train, word_to_vec_model, card_dict)\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "# Itere sobre as primeiras 45 entradas do DataLoader\n",
    "for i, (inputs, labels, mascara) in enumerate(dataloader):\n",
    "    if i < 45:\n",
    "        print(f\"--- Entrada {i+1} ---\")\n",
    "        \n",
    "        # Converta os embeddings para nomes\n",
    "        input_names = [MagicDataset.embedding_para_nome(embedding.numpy(), word_to_vec_model) for embedding in inputs.squeeze(0)]\n",
    "        \n",
    "        # Converta o índice da label para o nome usando a função indice_para_nome\n",
    "        label_name = indice_para_nome(labels.item(), card_dict)\n",
    "        print(labels.item())\n",
    "        print(\"Inputs:\", input_names)\n",
    "        print(\"Label:\", label_name)\n",
    "        print(\"Máscara:\", mascara)\n",
    "        print(\"\\n\")\n",
    "        break\n",
    "    else:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciar o modelo LSTM\n",
    "from torch import nn\n",
    "from net_architectures.mlp import *\n",
    "#model = LSTMModel()\n",
    "model = FeedForwardModel()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Average Loss: 1.3312, Epoch Acuracy: 0.5414\n",
      "Epoch [2/20], Average Loss: 1.0875, Epoch Acuracy: 0.6028\n",
      "Epoch [3/20], Average Loss: 1.0253, Epoch Acuracy: 0.6216\n",
      "Epoch [4/20], Average Loss: 0.9978, Epoch Acuracy: 0.6303\n",
      "Epoch [5/20], Average Loss: 0.9830, Epoch Acuracy: 0.6349\n",
      "Epoch [6/20], Average Loss: 0.9738, Epoch Acuracy: 0.6377\n",
      "Epoch [7/20], Average Loss: 0.9678, Epoch Acuracy: 0.6394\n",
      "Epoch [8/20], Average Loss: 0.9636, Epoch Acuracy: 0.6404\n",
      "Epoch [9/20], Average Loss: 0.9599, Epoch Acuracy: 0.6415\n",
      "Epoch [10/20], Average Loss: 0.9570, Epoch Acuracy: 0.6425\n",
      "Epoch [11/20], Average Loss: 0.9545, Epoch Acuracy: 0.6431\n",
      "Epoch [12/20], Average Loss: 0.9524, Epoch Acuracy: 0.6436\n",
      "Epoch [13/20], Average Loss: 0.9507, Epoch Acuracy: 0.6442\n",
      "Epoch [14/20], Average Loss: 0.9487, Epoch Acuracy: 0.6446\n",
      "Epoch [15/20], Average Loss: 0.9476, Epoch Acuracy: 0.6452\n",
      "Epoch [16/20], Average Loss: 0.9457, Epoch Acuracy: 0.6456\n",
      "Epoch [17/20], Average Loss: 0.9448, Epoch Acuracy: 0.6460\n",
      "Epoch [18/20], Average Loss: 0.9435, Epoch Acuracy: 0.6462\n",
      "Epoch [19/20], Average Loss: 0.9423, Epoch Acuracy: 0.6466\n",
      "Epoch [20/20], Average Loss: 0.9416, Epoch Acuracy: 0.6466\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from dataset_class import *\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Defina os hiperparâmetros\n",
    "num_epochs = 20\n",
    "batch_size = 32\n",
    "model_name = 'model_4'\n",
    "\n",
    "# Configurar o TensorBoard SummaryWriter para escrever logs na pasta 'runs'\n",
    "log_dir = './runs/'+model_name+'/'\n",
    "writer = SummaryWriter(log_dir=log_dir)\n",
    "\n",
    "# Defina um diretório para salvar os checkpoints\n",
    "checkpoint_dir = 'checkpoints'\n",
    "\n",
    "# Certifique-se de que o diretório exista (ou crie-o)\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir)\n",
    "\n",
    "# Criar o dataset e o DataLoader\n",
    "dataset = MagicDataset(df_train, word_to_vec_model, card_dict)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Mover o modelo para a GPU\n",
    "model.to(device)\n",
    "\n",
    "# Ciclo de treinamento\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    for i, (inputs, labels, mascara) in enumerate(dataloader):\n",
    "        # Mover as entradas e rótulos para a GPU\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        mascara = mascara.to(device)\n",
    "\n",
    "        # Zerar os gradientes\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward\n",
    "        outputs = model(inputs, mascara)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Acumular a perda\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Backward\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Calcular acertos\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct_predictions += (predicted == labels).sum().item()\n",
    "        total_samples += labels.size(0)\n",
    "\n",
    "    # Calcular e imprimir a perda média e a acurácia da época\n",
    "    average_loss = total_loss / len(dataloader)\n",
    "    epoch_accuracy = correct_predictions / total_samples\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Average Loss: {average_loss:.4f}, Epoch Acuracy: {epoch_accuracy:.4f}\")\n",
    "\n",
    "    # Registrar no TensorBoard\n",
    "    writer.add_scalar('Epoch Accuracy', epoch_accuracy, epoch)\n",
    "    writer.add_scalar('Epoch Loss', average_loss, epoch)\n",
    "\n",
    "    # Salvar o estado do modelo a cada 5 épocas\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        checkpoint = {\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': average_loss\n",
    "        }\n",
    "        checkpoint_path = os.path.join(checkpoint_dir, f'{model_name}_checkpoint_epoch_{epoch + 1}.pt')\n",
    "        torch.save(checkpoint, checkpoint_path)\n",
    "\n",
    "# Fechar o writer após terminar o treinamento\n",
    "writer.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mtg_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
