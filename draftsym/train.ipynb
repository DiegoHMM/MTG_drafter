{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorboard in /home/diego/miniconda3/envs/mtg_env/lib/python3.10/site-packages (2.14.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/diego/miniconda3/envs/mtg_env/lib/python3.10/site-packages (from tensorboard) (3.5)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /home/diego/miniconda3/envs/mtg_env/lib/python3.10/site-packages (from tensorboard) (1.0.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/diego/miniconda3/envs/mtg_env/lib/python3.10/site-packages (from tensorboard) (2.23.3)\n",
      "Requirement already satisfied: six>1.9 in /home/diego/miniconda3/envs/mtg_env/lib/python3.10/site-packages (from tensorboard) (1.16.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/diego/miniconda3/envs/mtg_env/lib/python3.10/site-packages (from tensorboard) (3.0.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /home/diego/miniconda3/envs/mtg_env/lib/python3.10/site-packages (from tensorboard) (1.59.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in /home/diego/miniconda3/envs/mtg_env/lib/python3.10/site-packages (from tensorboard) (2.0.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/diego/miniconda3/envs/mtg_env/lib/python3.10/site-packages (from tensorboard) (2.28.1)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /home/diego/miniconda3/envs/mtg_env/lib/python3.10/site-packages (from tensorboard) (1.26.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/diego/miniconda3/envs/mtg_env/lib/python3.10/site-packages (from tensorboard) (65.6.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/diego/miniconda3/envs/mtg_env/lib/python3.10/site-packages (from tensorboard) (0.7.1)\n",
      "Requirement already satisfied: protobuf>=3.19.6 in /home/diego/miniconda3/envs/mtg_env/lib/python3.10/site-packages (from tensorboard) (4.24.4)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/diego/miniconda3/envs/mtg_env/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard) (4.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/diego/miniconda3/envs/mtg_env/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard) (0.3.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/diego/miniconda3/envs/mtg_env/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard) (5.3.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/diego/miniconda3/envs/mtg_env/lib/python3.10/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard) (1.3.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/diego/miniconda3/envs/mtg_env/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/diego/miniconda3/envs/mtg_env/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/diego/miniconda3/envs/mtg_env/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/diego/miniconda3/envs/mtg_env/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard) (2.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/diego/miniconda3/envs/mtg_env/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /home/diego/miniconda3/envs/mtg_env/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/diego/miniconda3/envs/mtg_env/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from lstm import *\n",
    "from mlp import *\n",
    "from gensim.models import Word2Vec\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar se a GPU está disponível\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi = open('config.yaml', 'r')\n",
    "card_dict = yaml.load(fi, Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indice_para_nome(indice, cards_dict):\n",
    "    \"\"\"Converte um índice para o nome da carta correspondente usando o dicionário de cartas.\"\"\"\n",
    "    try:\n",
    "        return cards_dict['cards_list'][indice]\n",
    "    except IndexError:\n",
    "        raise ValueError(f\"Índice {indice} fora do alcance do dicionário de cartas.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train_df.csv')\n",
    "df_train = df_train.drop(columns=['Unnamed: 0.1', 'Unnamed: 0'])\n",
    "#df_train = df_train[:90]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_vec_model = Word2Vec.load(\"card2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Entrada 1 ---\n",
      "70\n",
      "Inputs: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Label: Skyrider_Patrol\n",
      "Máscara: tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0.,\n",
      "         0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "         1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from dataset_class import *\n",
    "\n",
    "# Crie o dataset e o DataLoader\n",
    "dataset = MagicDataset(df_train, word_to_vec_model, card_dict)\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "# Itere sobre as primeiras 45 entradas do DataLoader\n",
    "for i, (inputs, labels, mascara) in enumerate(dataloader):\n",
    "    if i < 45:\n",
    "        print(f\"--- Entrada {i+1} ---\")\n",
    "        \n",
    "        # Converta os embeddings para nomes\n",
    "        input_names = [MagicDataset.embedding_para_nome(embedding.numpy(), word_to_vec_model) for embedding in inputs.squeeze(0)]\n",
    "        \n",
    "        # Converta o índice da label para o nome usando a função indice_para_nome\n",
    "        label_name = indice_para_nome(labels.item(), card_dict)\n",
    "        print(labels.item())\n",
    "        print(\"Inputs:\", input_names)\n",
    "        print(\"Label:\", label_name)\n",
    "        print(\"Máscara:\", mascara)\n",
    "        print(\"\\n\")\n",
    "        break\n",
    "    else:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciar o modelo LSTM\n",
    "from torch import nn\n",
    "#model = LSTMModel()\n",
    "model = FeedForwardModel()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diego/Documentos/MTG_drafter/draftsym/dataset_class.py:66: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
      "  X = torch.tensor(pool_embedding, dtype=torch.float32)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/diego/Documentos/MTG_drafter/draftsym/train.ipynb Cell 10\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/diego/Documentos/MTG_drafter/draftsym/train.ipynb#X10sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m total_loss \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/diego/Documentos/MTG_drafter/draftsym/train.ipynb#X10sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m total_batches \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/diego/Documentos/MTG_drafter/draftsym/train.ipynb#X10sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m \u001b[39mfor\u001b[39;00m i, (inputs, labels, mascara) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(dataloader):\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/diego/Documentos/MTG_drafter/draftsym/train.ipynb#X10sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m     \u001b[39m# Mover as entradas e rótulos para a GPU\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/diego/Documentos/MTG_drafter/draftsym/train.ipynb#X10sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m     inputs \u001b[39m=\u001b[39m inputs\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/diego/Documentos/MTG_drafter/draftsym/train.ipynb#X10sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m     labels \u001b[39m=\u001b[39m labels\u001b[39m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/miniconda3/envs/mtg_env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    632\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 633\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    634\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    635\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    636\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/envs/mtg_env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    676\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 677\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    678\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    679\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/miniconda3/envs/mtg_env/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/miniconda3/envs/mtg_env/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/Documentos/MTG_drafter/draftsym/dataset_class.py:58\u001b[0m, in \u001b[0;36mMagicDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, idx):\n\u001b[1;32m     56\u001b[0m     row \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataframe\u001b[39m.\u001b[39miloc[idx]\n\u001b[0;32m---> 58\u001b[0m     pool \u001b[39m=\u001b[39m MagicDataset\u001b[39m.\u001b[39;49mstring_para_lista(row[\u001b[39m'\u001b[39;49m\u001b[39mpool\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[1;32m     59\u001b[0m     available \u001b[39m=\u001b[39m MagicDataset\u001b[39m.\u001b[39mstring_para_lista(row[\u001b[39m'\u001b[39m\u001b[39mavailable\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m     60\u001b[0m     mascara \u001b[39m=\u001b[39m MagicDataset\u001b[39m.\u001b[39mcriar_mascara_disponibilidade(available, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcard_dict)\n",
      "File \u001b[0;32m~/Documentos/MTG_drafter/draftsym/dataset_class.py:36\u001b[0m, in \u001b[0;36mMagicDataset.string_para_lista\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[1;32m     34\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstring_para_lista\u001b[39m(s):\n\u001b[1;32m     35\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 36\u001b[0m         \u001b[39mreturn\u001b[39;00m ast\u001b[39m.\u001b[39;49mliteral_eval(s)\n\u001b[1;32m     37\u001b[0m     \u001b[39mexcept\u001b[39;00m (\u001b[39mSyntaxError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[1;32m     38\u001b[0m         \u001b[39mreturn\u001b[39;00m []\n",
      "File \u001b[0;32m~/miniconda3/envs/mtg_env/lib/python3.10/ast.py:64\u001b[0m, in \u001b[0;36mliteral_eval\u001b[0;34m(node_or_string)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[39mEvaluate an expression node or a string containing only a Python\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[39mexpression.  The string or node provided may only consist of the following\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[39mCaution: A complex expression can overflow the C stack and cause a crash.\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(node_or_string, \u001b[39mstr\u001b[39m):\n\u001b[0;32m---> 64\u001b[0m     node_or_string \u001b[39m=\u001b[39m parse(node_or_string\u001b[39m.\u001b[39;49mlstrip(\u001b[39m\"\u001b[39;49m\u001b[39m \u001b[39;49m\u001b[39m\\t\u001b[39;49;00m\u001b[39m\"\u001b[39;49m), mode\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39meval\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     65\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(node_or_string, Expression):\n\u001b[1;32m     66\u001b[0m     node_or_string \u001b[39m=\u001b[39m node_or_string\u001b[39m.\u001b[39mbody\n",
      "File \u001b[0;32m~/miniconda3/envs/mtg_env/lib/python3.10/ast.py:50\u001b[0m, in \u001b[0;36mparse\u001b[0;34m(source, filename, mode, type_comments, feature_version)\u001b[0m\n\u001b[1;32m     48\u001b[0m     feature_version \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\n\u001b[1;32m     49\u001b[0m \u001b[39m# Else it should be an int giving the minor version for 3.x.\u001b[39;00m\n\u001b[0;32m---> 50\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcompile\u001b[39;49m(source, filename, mode, flags,\n\u001b[1;32m     51\u001b[0m                _feature_version\u001b[39m=\u001b[39;49mfeature_version)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from dataset_class import *\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Defina os hiperparâmetros\n",
    "num_epochs = 300\n",
    "batch_size = 8\n",
    "\n",
    "# Configurar o TensorBoard SummaryWriter para escrever logs na pasta 'runs'\n",
    "log_dir = './runs'\n",
    "writer = SummaryWriter(log_dir=log_dir)\n",
    "\n",
    "# Defina um diretório para salvar os checkpoints\n",
    "checkpoint_dir = 'checkpoints'\n",
    "\n",
    "# Certifique-se de que o diretório exista (ou crie-o)\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir)\n",
    "\n",
    "# Criar o dataset e o DataLoader\n",
    "dataset = MagicDataset(df_train, word_to_vec_model, card_dict)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Definir seu modelo, otimizador e função de perda aqui\n",
    "# Certifique-se de inicializar 'model' e 'optimizer' corretamente\n",
    "\n",
    "# Mover o modelo para a GPU\n",
    "model.to(device)\n",
    "\n",
    "# Defina uma variável para rastrear o número total de iterações\n",
    "total_iterations = 0\n",
    "\n",
    "# Ciclo de treinamento\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0.0\n",
    "    total_batches = 0\n",
    "\n",
    "    for i, (inputs, labels, mascara) in enumerate(dataloader):\n",
    "        # Mover as entradas e rótulos para a GPU\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        mascara = mascara.to(device)\n",
    "\n",
    "        # Zerar os gradientes\n",
    "        optimizer.zero_grad()\n",
    "        # Forward\n",
    "        outputs = model(inputs, mascara)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Acumular a perda\n",
    "        total_loss += loss.item()\n",
    "        total_batches += 1\n",
    "\n",
    "        # Backward\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Atualizar o número total de iterações\n",
    "        total_iterations += 1\n",
    "\n",
    "        # Salvar um checkpoint a cada determinado número de iterações (por exemplo, a cada 1000 iterações)\n",
    "        if total_iterations % 100000 == 0:\n",
    "            checkpoint = {\n",
    "                'epoch': epoch,\n",
    "                'total_iterations': total_iterations,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': loss.item()\n",
    "            }\n",
    "            checkpoint_path = os.path.join(checkpoint_dir, f'checkpoint_{total_iterations}.pt')\n",
    "            torch.save(checkpoint, checkpoint_path)\n",
    "\n",
    "    # Calcular a perda média da época e registrar no TensorBoard\n",
    "    average_loss = total_loss / total_batches\n",
    "    writer.add_scalar('Epoch Loss', average_loss, epoch)\n",
    "\n",
    "    # Imprimir a perda média da época\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Average Loss: {average_loss:.4f}\")\n",
    "\n",
    "# Fechar o writer após terminar o treinamento\n",
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from lstm import *\n",
    "from mlp import *\n",
    "from gensim.models import Word2Vec\n",
    "import pandas as pd\n",
    "\n",
    "df_test = pd.read_csv('test_df.csv')\n",
    "df_test = df_test.drop(columns=['Unnamed: 0.1', 'Unnamed: 0'])\n",
    "#df_train = df_train[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi = open('config.yaml', 'r')\n",
    "card_dict = yaml.load(fi, Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'checkpoints/checkpoint_best.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/diego/Documentos/MTG_drafter/draftsym/train.ipynb Cell 14\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/diego/Documentos/MTG_drafter/draftsym/train.ipynb#X16sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m optimizer \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m  \u001b[39m# Você não precisa do otimizador durante o teste, mas é útil para carregar o modelo a partir do checkpoint\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/diego/Documentos/MTG_drafter/draftsym/train.ipynb#X16sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39m# Carregar o modelo do checkpoint\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/diego/Documentos/MTG_drafter/draftsym/train.ipynb#X16sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m model, _, _, _, _ \u001b[39m=\u001b[39m load_model_from_checkpoint(model, optimizer, checkpoint_path)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/diego/Documentos/MTG_drafter/draftsym/train.ipynb#X16sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39m# Mover modelo para o dispositivo apropriado\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/diego/Documentos/MTG_drafter/draftsym/train.ipynb#X16sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m model\u001b[39m.\u001b[39mto(device)\n",
      "\u001b[1;32m/home/diego/Documentos/MTG_drafter/draftsym/train.ipynb Cell 14\u001b[0m line \u001b[0;36m8\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/diego/Documentos/MTG_drafter/draftsym/train.ipynb#X16sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_model_from_checkpoint\u001b[39m(model, optimizer, checkpoint_path):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/diego/Documentos/MTG_drafter/draftsym/train.ipynb#X16sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     checkpoint \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mload(checkpoint_path)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/diego/Documentos/MTG_drafter/draftsym/train.ipynb#X16sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     model\u001b[39m.\u001b[39mload_state_dict(checkpoint[\u001b[39m'\u001b[39m\u001b[39mmodel_state_dict\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/diego/Documentos/MTG_drafter/draftsym/train.ipynb#X16sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     \u001b[39mif\u001b[39;00m optimizer:\n",
      "File \u001b[0;32m~/miniconda3/envs/mtg_env/lib/python3.10/site-packages/torch/serialization.py:791\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m pickle_load_args\u001b[39m.\u001b[39mkeys():\n\u001b[1;32m    789\u001b[0m     pickle_load_args[\u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m--> 791\u001b[0m \u001b[39mwith\u001b[39;00m _open_file_like(f, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m opened_file:\n\u001b[1;32m    792\u001b[0m     \u001b[39mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m    793\u001b[0m         \u001b[39m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m    794\u001b[0m         \u001b[39m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m    795\u001b[0m         \u001b[39m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m    796\u001b[0m         orig_position \u001b[39m=\u001b[39m opened_file\u001b[39m.\u001b[39mtell()\n",
      "File \u001b[0;32m~/miniconda3/envs/mtg_env/lib/python3.10/site-packages/torch/serialization.py:271\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    270\u001b[0m     \u001b[39mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 271\u001b[0m         \u001b[39mreturn\u001b[39;00m _open_file(name_or_buffer, mode)\n\u001b[1;32m    272\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    273\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m mode:\n",
      "File \u001b[0;32m~/miniconda3/envs/mtg_env/lib/python3.10/site-packages/torch/serialization.py:252\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, name, mode):\n\u001b[0;32m--> 252\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\u001b[39mopen\u001b[39;49m(name, mode))\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'checkpoints/checkpoint_best.pt'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from dataset_class import *\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Carregar o modelo e otimizador do checkpoint\n",
    "def load_model_from_checkpoint(model, optimizer, checkpoint_path):\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    if optimizer:\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    epoch = checkpoint['epoch']\n",
    "    total_iterations = checkpoint['total_iterations']\n",
    "    loss = checkpoint['loss']\n",
    "    return model, optimizer, epoch, total_iterations, loss\n",
    "\n",
    "# Configurações\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "checkpoint_path = 'checkpoints/checkpoint_best.pt'  # Aqui, assumindo que você deseja carregar o \"melhor\" checkpoint\n",
    "\n",
    "# Instanciar modelo e otimizador\n",
    "model = FeedForwardModel()  # Substitua pelo nome correto da sua classe de modelo\n",
    "optimizer = None  # Você não precisa do otimizador durante o teste, mas é útil para carregar o modelo a partir do checkpoint\n",
    "\n",
    "# Carregar o modelo do checkpoint\n",
    "model, _, _, _, _ = load_model_from_checkpoint(model, optimizer, checkpoint_path)\n",
    "\n",
    "# Mover modelo para o dispositivo apropriado\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Criar o dataset e o DataLoader para teste\n",
    "dataset_test = MagicDataset(df_test, word_to_vec_model, card_dict)  # Aqui, assumindo que 'df_test' é o seu dataframe de teste\n",
    "test_loader = DataLoader(dataset_test, batch_size=32, shuffle=False)\n",
    "\n",
    "# Variáveis para rastrear a precisão\n",
    "total_samples = 0\n",
    "correct_samples = 0\n",
    "\n",
    "# Ciclo de teste\n",
    "with torch.no_grad():\n",
    "    for i, (inputs, labels, mascara) in enumerate(test_loader):\n",
    "        # Mover entradas e rótulos para o dispositivo\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        mascara = mascara.to(device)\n",
    "        \n",
    "        # Predição\n",
    "        outputs = model(inputs, mascara)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        \n",
    "        # Atualizar contadores de precisão\n",
    "        total_samples += labels.size(0)\n",
    "        correct_samples += (predicted == labels).sum().item()\n",
    "\n",
    "        # Opcional: Imprimir estatísticas a cada 100 lotes\n",
    "        if i % 100 == 0:\n",
    "            print(f\"Batch [{i+1}/{len(test_loader)}] - Accuracy: {100 * correct_samples / total_samples:.2f}%\")\n",
    "\n",
    "# Imprimir precisão final\n",
    "print(f\"Total Accuracy: {100 * correct_samples / total_samples:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mtg_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
